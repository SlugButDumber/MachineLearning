{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "X = dataset.iloc[:, 1:-6].values\n",
    "y = dataset.iloc[:, -6:-4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_dataset = pd.read_csv('test.csv')\n",
    "X_submission = Test_dataset.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = sc.transform(X_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models and predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CATBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For EC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "regressor_cat1 = CatBoostRegressor(learning_rate=0.007573490922788006,\n",
    "                               depth=6,\n",
    "                               subsample=0.8147194080189883,\n",
    "                               colsample_bylevel=0.5311715736954817,\n",
    "                               min_data_in_leaf=56)\n",
    "regressor_cat1.fit(X, y[:, 0])\n",
    "\n",
    "y_pred_cat1 = regressor_cat1.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_cat2 = CatBoostRegressor(learning_rate=0.01632700367902254,\n",
    "                               depth=3,\n",
    "                               subsample=0.6001420520780691,\n",
    "                               colsample_bylevel=0.5074737933892164,\n",
    "                               min_data_in_leaf=75)\n",
    "regressor_cat2.fit(X, y[:, 1])\n",
    "\n",
    "y_pred_cat2 = regressor_cat2.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For EC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "regressor_xgb1 = XGBRegressor(max_depth=2,\n",
    "                          learning_rate = 0.06888600413221835,\n",
    "                          n_estimators=201,\n",
    "                          min_child_weight=3,\n",
    "                          gamma=0.0356537935597181,\n",
    "                          subsample=0.919214627352363,\n",
    "                          colsample_bytree=0.6479551640312314,\n",
    "                          reg_alpha=0.4805888998558167,\n",
    "                          reg_lambda=0.2234388007912691)\n",
    "regressor_xgb1.fit(X, y[:, 0])\n",
    "\n",
    "y_pred_xgb1 = regressor_xgb1.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_xgb2 = XGBRegressor(max_depth=4,\n",
    "                          learning_rate =0.04847250666447861,\n",
    "                          n_estimators=279,\n",
    "                          min_child_weight=3,\n",
    "                          gamma=0.847297033527792,\n",
    "                          subsample=0.7434346764669405,\n",
    "                          colsample_bytree=0.09679280536046835,\n",
    "                          reg_alpha=0.894699651732954,\n",
    "                          reg_lambda=0.6729634389162842)\n",
    "regressor_xgb2.fit(X, y[:, 1])\n",
    "\n",
    "y_pred_xgb2 = regressor_xgb2.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating arrays for ANNs inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in1 = np.concatenate((y_pred_cat1.reshape(len(y_pred_cat1), 1),\n",
    "                        y_pred_xgb1.reshape(len(y_pred_xgb1), 1)),\n",
    "                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_in1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in2 = np.concatenate((y_pred_cat2.reshape(len(y_pred_cat2), 1),\n",
    "                        y_pred_xgb2.reshape(len(y_pred_xgb2), 1)),\n",
    "                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_in2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1 = tf.keras.models.Sequential()\n",
    "\n",
    "ann1.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "\n",
    "ann1.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "\n",
    "ann1.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann2 = tf.keras.models.Sequential()\n",
    "\n",
    "ann2.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "\n",
    "ann2.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "\n",
    "ann2.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_in1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "ann1.fit(y_in1, y[:,0], batch_size = 32, epochs = 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann2.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "ann2.fit(y_in2, y[:, 1], batch_size = 32, epochs = 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Test Set Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission_cat1 = regressor_cat1.predict(X_submission)\n",
    "y_submission_cat2 = regressor_cat2.predict(X_submission)\n",
    "y_submission_xgb1 = regressor_xgb1.predict(X_submission)\n",
    "y_submission_xgb2 = regressor_xgb2.predict(X_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission1 = np.concatenate((y_submission_cat1.reshape(len(y_submission_cat1), 1),\n",
    "                                y_submission_xgb1.reshape(len(y_submission_xgb1), 1)),\n",
    "                                1)\n",
    "\n",
    "y_submission2 = np.concatenate((y_submission_cat2.reshape(len(y_submission_cat2), 1),\n",
    "                                y_submission_xgb2.reshape(len(y_submission_xgb2), 1)),\n",
    "                                1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = ann1.predict(y_submission1)\n",
    "y_pred2 = ann2.predict(y_submission2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':Test_dataset['id'],'EC1': y_pred1.flatten(), 'EC2': y_pred2.flatten()})\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
